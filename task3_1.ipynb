{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSq34M+qfGbCCIW42Hw3fb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasmis1229/task3-1/blob/main/task3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ybzvy3RLvdCZ"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from scipy import sparse\n",
        "\n",
        "def build_cooccurrence_matrix(tokenized_corpus, word_to_id, window_size=2):\n",
        "    vocab_size = len(word_to_id)\n",
        "    cooccurrence_dict = defaultdict(float)\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "        sentence_length = len(sentence)\n",
        "        for i, center_word in enumerate(sentence):\n",
        "            if center_word not in word_to_id:\n",
        "                continue\n",
        "            center_id = word_to_id[center_word]\n",
        "            for j in range(max(0, i - window_size), min(sentence_length, i + window_size + 1)):\n",
        "                if i != j:\n",
        "                    context_word = sentence[j]\n",
        "                    if context_word in word_to_id:\n",
        "                        context_id = word_to_id[context_word]\n",
        "                        distance = abs(j - i)\n",
        "                        weight = 1.0 / distance\n",
        "                        cooccurrence_dict[(center_id, context_id)] += weight\n",
        "\n",
        "    row, col, data = zip(*[(i, j, v) for (i, j), v in cooccurrence_dict.items()])\n",
        "    return sparse.csr_matrix((data, (row, col)), shape=(vocab_size, vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_sizes = [1, 3, 5]\n",
        "matrices = {\n",
        "    w: build_cooccurrence_matrix(tokenized_corpus, word_to_id, window_size=w)\n",
        "    for w in window_sizes\n",
        "}"
      ],
      "metadata": {
        "id": "OB0GDsFi0v8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_words = list(word_to_id.keys())[:20]\n",
        "indices = [word_to_id[w] for w in top_words]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "for idx, w in enumerate(window_sizes):\n",
        "    mat = matrices[w][indices, :][:, indices].todense()\n",
        "    sns.heatmap(mat, xticklabels=top_words, yticklabels=top_words, ax=axes[idx], cmap=\"Blues\")\n",
        "    axes[idx].set_title(f\"윈도우 크기: {w}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6WWpYogC0llK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}